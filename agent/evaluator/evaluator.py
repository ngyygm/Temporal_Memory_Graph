"""
Evaluator è¯„ä¼°å™¨

è´Ÿè´£åˆ¤æ–­å½“å‰æ”¶é›†çš„è®°å¿†æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜
"""
import json
import re
from typing import List, Dict, Any, Optional

from ..llm.base import BaseLLMClient
from ..models import EvaluationResult
from ..context.reasoning_cache import ReasoningState, GoalStatus
from ..logger import AgentLogger, get_logger
from .prompts import (
    EVALUATOR_SYSTEM_PROMPT,
    EVALUATOR_REQUEST_TEMPLATE,
    EVALUATOR_REQUEST_WITH_REASONING,
    REASONING_EVALUATOR_SYSTEM_PROMPT,
    format_collected_memories
)


class Evaluator:
    """è¯„ä¼°å™¨ - åˆ¤æ–­è®°å¿†æ˜¯å¦è¶³å¤Ÿ"""
    
    def __init__(
        self,
        llm_client: BaseLLMClient,
        logger: Optional[AgentLogger] = None
    ):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.llm_client = llm_client
        self.logger = logger or get_logger()
    
    def evaluate(
        self,
        question: str,
        collected_memories: List[Dict[str, Any]],
        iteration: int = 1,
        reasoning_state: Optional[ReasoningState] = None
    ) -> EvaluationResult:
        """
        è¯„ä¼°å½“å‰æ”¶é›†çš„è®°å¿†æ˜¯å¦è¶³å¤Ÿ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            collected_memories: å·²æ”¶é›†çš„è®°å¿†
            iteration: å½“å‰è¿­ä»£æ¬¡æ•°
            reasoning_state: æ¨ç†çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        # æ ¼å¼åŒ–è®°å¿†
        memories_str = format_collected_memories(collected_memories)
        
        # æ ¹æ®æ˜¯å¦æœ‰æ¨ç†çŠ¶æ€é€‰æ‹©è¯„ä¼°æ–¹å¼
        if reasoning_state and reasoning_state.question_type.value != "direct":
            return self._evaluate_with_reasoning(
                question, memories_str, iteration, reasoning_state
            )
        
        # ç®€å•è¯„ä¼°
        request = EVALUATOR_REQUEST_TEMPLATE.format(
            question=question,
            collected_memories=memories_str,
            iteration=iteration
        )
        
        messages = [
            {"role": "system", "content": EVALUATOR_SYSTEM_PROMPT},
            {"role": "user", "content": request}
        ]
        
        self.logger.debug(f"Evaluator request: {request[:500]}...")
        response = self.llm_client.chat(messages)
        self.logger.debug(f"Evaluator response: {response.content[:500]}...")
        
        result = self._parse_response(response.content)
        self.logger.evaluate(result.is_sufficient, result.reasoning)
        
        return result
    
    def _evaluate_with_reasoning(
        self,
        question: str,
        memories_str: str,
        iteration: int,
        reasoning_state: ReasoningState
    ) -> EvaluationResult:
        """å¸¦æ¨ç†çŠ¶æ€çš„è¯„ä¼°"""
        # æ ¼å¼åŒ–å­ç›®æ ‡
        sub_goals_str = self._format_sub_goals(reasoning_state.sub_goals)
        
        # æ ¼å¼åŒ–å·²çŸ¥äº‹å®
        known_facts_str = self._format_known_facts(
            reasoning_state.known_facts,
            reasoning_state.entity_facts,
            reasoning_state.relation_facts
        )
        
        # æ ¼å¼åŒ–ç¼ºå¤±ä¿¡æ¯
        missing_str = "\n".join(f"- {info}" for info in reasoning_state.missing_info) or "æ— "
        
        # æ ¼å¼åŒ–å‡è®¾
        hypotheses_str = self._format_hypotheses(reasoning_state.hypotheses)
        
        request = EVALUATOR_REQUEST_WITH_REASONING.format(
            question=question,
            question_type=reasoning_state.question_type.value,
            sub_goals=sub_goals_str,
            known_facts=known_facts_str,
            missing_info=missing_str,
            hypotheses=hypotheses_str,
            collected_memories=memories_str,
            iteration=iteration
        )
        
        messages = [
            {"role": "system", "content": REASONING_EVALUATOR_SYSTEM_PROMPT},
            {"role": "user", "content": request}
        ]
        
        self.logger.debug(f"Reasoning evaluator request: {request[:500]}...")
        response = self.llm_client.chat(messages)
        self.logger.debug(f"Reasoning evaluator response: {response.content[:500]}...")
        
        result = self._parse_reasoning_response(response.content)
        self.logger.evaluate(result.is_sufficient, result.reasoning)
        
        return result
    
    async def aevaluate(
        self,
        question: str,
        collected_memories: List[Dict[str, Any]],
        iteration: int = 1,
        reasoning_state: Optional[ReasoningState] = None
    ) -> EvaluationResult:
        """å¼‚æ­¥ç‰ˆæœ¬çš„è¯„ä¼°"""
        memories_str = format_collected_memories(collected_memories)
        
        if reasoning_state and reasoning_state.question_type.value != "direct":
            return await self._aevaluate_with_reasoning(
                question, memories_str, iteration, reasoning_state
            )
        
        request = EVALUATOR_REQUEST_TEMPLATE.format(
            question=question,
            collected_memories=memories_str,
            iteration=iteration
        )
        
        messages = [
            {"role": "system", "content": EVALUATOR_SYSTEM_PROMPT},
            {"role": "user", "content": request}
        ]
        
        response = await self.llm_client.achat(messages)
        result = self._parse_response(response.content)
        self.logger.evaluate(result.is_sufficient, result.reasoning)
        
        return result
    
    async def _aevaluate_with_reasoning(
        self,
        question: str,
        memories_str: str,
        iteration: int,
        reasoning_state: ReasoningState
    ) -> EvaluationResult:
        """å¼‚æ­¥å¸¦æ¨ç†çŠ¶æ€çš„è¯„ä¼°"""
        sub_goals_str = self._format_sub_goals(reasoning_state.sub_goals)
        known_facts_str = self._format_known_facts(
            reasoning_state.known_facts,
            reasoning_state.entity_facts,
            reasoning_state.relation_facts
        )
        missing_str = "\n".join(f"- {info}" for info in reasoning_state.missing_info) or "æ— "
        hypotheses_str = self._format_hypotheses(reasoning_state.hypotheses)
        
        request = EVALUATOR_REQUEST_WITH_REASONING.format(
            question=question,
            question_type=reasoning_state.question_type.value,
            sub_goals=sub_goals_str,
            known_facts=known_facts_str,
            missing_info=missing_str,
            hypotheses=hypotheses_str,
            collected_memories=memories_str,
            iteration=iteration
        )
        
        messages = [
            {"role": "system", "content": REASONING_EVALUATOR_SYSTEM_PROMPT},
            {"role": "user", "content": request}
        ]
        
        response = await self.llm_client.achat(messages)
        result = self._parse_reasoning_response(response.content)
        self.logger.evaluate(result.is_sufficient, result.reasoning)
        
        return result
    
    def _format_sub_goals(self, sub_goals: List) -> str:
        """æ ¼å¼åŒ–å­ç›®æ ‡"""
        if not sub_goals:
            return "æ— å­ç›®æ ‡"
        
        lines = []
        for goal in sub_goals:
            status_icon = {
                GoalStatus.PENDING: "â³",
                GoalStatus.IN_PROGRESS: "ğŸ”„",
                GoalStatus.COMPLETED: "âœ…",
                GoalStatus.FAILED: "âŒ"
            }.get(goal.status, "?")
            lines.append(f"{status_icon} {goal.description}")
            if goal.result:
                lines.append(f"   ç»“æœ: {str(goal.result)[:100]}")
        
        return "\n".join(lines)
    
    def _format_known_facts(
        self,
        known_facts: Dict,
        entity_facts: Dict,
        relation_facts: Dict
    ) -> str:
        """æ ¼å¼åŒ–å·²çŸ¥äº‹å®"""
        lines = []
        
        if known_facts:
            lines.append("**ä¸€èˆ¬äº‹å®:**")
            for key, value in list(known_facts.items())[:10]:
                lines.append(f"- {key}: {str(value)[:100]}")
        
        if entity_facts:
            lines.append("\n**å®ä½“ä¿¡æ¯:**")
            for eid, facts in list(entity_facts.items())[:5]:
                name = facts.get("name", eid)
                lines.append(f"- {name}: {facts.get('content', '')[:100]}...")
        
        if relation_facts:
            lines.append("\n**å…³ç³»ä¿¡æ¯:**")
            for rid, facts in list(relation_facts.items())[:5]:
                e1 = facts.get("entity1_name", "?")
                e2 = facts.get("entity2_name", "?")
                lines.append(f"- {e1} -- {e2}: {facts.get('content', '')[:80]}...")
        
        return "\n".join(lines) or "æ— "
    
    def _format_hypotheses(self, hypotheses: List) -> str:
        """æ ¼å¼åŒ–å‡è®¾"""
        if not hypotheses:
            return "æ— "
        
        lines = []
        for hyp in hypotheses:
            verified_str = "?" if hyp.verified is None else ("âœ“" if hyp.verified else "âœ—")
            lines.append(f"- [{verified_str}] [{hyp.confidence:.0%}] {hyp.content}")
        
        return "\n".join(lines)
    
    def _parse_reasoning_response(self, content: str) -> EvaluationResult:
        """è§£ææ¨ç†è¯„ä¼°å“åº”"""
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)```', content)
        if json_match:
            json_str = json_match.group(1).strip()
        else:
            json_str = content.strip()
        
        try:
            result = json.loads(json_str)
        except json.JSONDecodeError:
            # å°è¯•ä»æ–‡æœ¬æ¨æ–­
            is_sufficient = any(keyword in content.lower() for keyword in 
                              ["è¶³å¤Ÿ", "å……è¶³", "sufficient", "å¯ä»¥æ¨ç†", "can_reason"])
            
            return EvaluationResult(
                is_sufficient=is_sufficient,
                reasoning=content[:500],
                next_action="" if is_sufficient else "ç»§ç»­æŸ¥è¯¢ç›¸å…³ä¿¡æ¯"
            )
        
        # æå–æ¨ç†å¯è¡Œæ€§
        reasoning_feasibility = result.get("reasoning_feasibility", {})
        can_reason = reasoning_feasibility.get("can_reason", False)
        
        # ç»¼åˆåˆ¤æ–­ï¼šä¿¡æ¯å……è¶³æˆ–å¯ä»¥æ¨ç†
        is_sufficient = result.get("is_sufficient", False) or can_reason
        
        # æå–é—®é¢˜ç±»å‹è°ƒæ•´å»ºè®®
        adjustment_info = result.get("question_type_adjustment", {})
        question_type_adjustment = None
        if adjustment_info.get("should_adjust", False):
            from agent.models import QuestionTypeAdjustment
            question_type_adjustment = QuestionTypeAdjustment(
                should_adjust=True,
                new_type=adjustment_info.get("new_type"),
                reason=adjustment_info.get("reason", "")
            )
        
        return EvaluationResult(
            is_sufficient=is_sufficient,
            reasoning=result.get("reasoning", ""),
            memories_to_keep=result.get("memories_to_keep", []),
            next_action=result.get("next_action", ""),
            question_type_adjustment=question_type_adjustment
        )
    
    def _parse_response(self, content: str) -> EvaluationResult:
        """è§£æ LLM å“åº”"""
        # å°è¯•æå– JSON
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)```', content)
        if json_match:
            json_str = json_match.group(1).strip()
        else:
            json_str = content.strip()
        
        try:
            result = json.loads(json_str)
        except json.JSONDecodeError:
            # å°è¯•ä»æ–‡æœ¬ä¸­æ¨æ–­ç»“æœ
            is_sufficient = any(keyword in content.lower() for keyword in 
                              ["è¶³å¤Ÿ", "å……è¶³", "sufficient", "å¯ä»¥å›ç­”", "enough"])
            
            return EvaluationResult(
                is_sufficient=is_sufficient,
                reasoning=content[:500],
                next_action="" if is_sufficient else "ç»§ç»­æŸ¥è¯¢ç›¸å…³ä¿¡æ¯"
            )
        
        return EvaluationResult(
            is_sufficient=result.get("is_sufficient", False),
            reasoning=result.get("reasoning", ""),
            memories_to_keep=result.get("memories_to_keep", []),
            next_action=result.get("next_action", "")
        )
    
    def quick_check(self, collected_memories: List[Dict[str, Any]]) -> bool:
        """
        å¿«é€Ÿæ£€æŸ¥ï¼ˆä¸è°ƒç”¨ LLMï¼‰
        
        ç”¨äºç®€å•åœºæ™¯çš„å¿«é€Ÿåˆ¤æ–­ï¼Œå¦‚ï¼š
        - æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•è®°å¿†
        - æ”¶é›†åˆ°äº†æ˜ç¡®çš„é”™è¯¯
        
        Args:
            collected_memories: å·²æ”¶é›†çš„è®°å¿†
            
        Returns:
            æ˜¯å¦éœ€è¦ç»§ç»­æŸ¥è¯¢ï¼ˆTrue = éœ€è¦ç»§ç»­ï¼‰
        """
        if not collected_memories:
            return True  # æ²¡æœ‰è®°å¿†ï¼Œéœ€è¦ç»§ç»­
        
        # æ£€æŸ¥æœ€åä¸€ä¸ªæŸ¥è¯¢ç»“æœ
        last_memory = collected_memories[-1]
        if isinstance(last_memory, dict):
            result = last_memory.get("result", {})
            if isinstance(result, dict):
                # å¦‚æœæœ€åä¸€ä¸ªæŸ¥è¯¢æ‰¾åˆ°äº†å®ä½“æˆ–å…³ç³»ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ¢ç´¢
                if result.get("entities") or result.get("relations"):
                    return True
                # å¦‚æœæŸ¥è¯¢æˆåŠŸä½†æ²¡æœ‰ç»“æœï¼Œå¯èƒ½éœ€è¦æ¢ä¸€ç§æŸ¥è¯¢æ–¹å¼
                if result.get("success") and result.get("count", 0) == 0:
                    return True
        
        return False
