"""
Orchestrator ç¼–æ’å™¨

è®°å¿†æ£€ç´¢ Agent çš„ä¸»å…¥å£ï¼Œåè°ƒ Plannerã€Executorã€Evaluatorã€Reasonerã€Summarizer çš„å·¥ä½œ
"""
import time
import asyncio
from typing import List, Dict, Any, Optional, Union
from pathlib import Path
import sys

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ processor
sys.path.insert(0, str(Path(__file__).parent.parent))

from .models import (
    AgentConfig, QueryResult, ToolCall, ToolResult,
    RetrievedMemory, Message
)
from .llm import create_llm_client, BaseLLMClient
from .llm.openai_client import MockLLMClient
from .planner import Planner
from .executor import Executor
from .executor.tool_registry import create_default_registry, ToolRegistry
from .evaluator import Evaluator
from .context import ContextManager, SmartCache, ReasoningCache, QuestionType
from .reasoner import Reasoner
from .summarizer import Summarizer
from .logger import AgentLogger, set_logger


class MemoryRetrievalAgent:
    """
    è®°å¿†æ£€ç´¢ Agent
    
    ä½¿ç”¨ ReAct å¾ªç¯ï¼ˆè§„åˆ’-æ‰§è¡Œ-è§‚å¯Ÿ-åˆ¤æ–­ï¼‰ä»æ—¶åºè®°å¿†å›¾è°±ä¸­æ£€ç´¢ç›¸å…³è®°å¿†ã€‚
    
    æ–°å¢åŠŸèƒ½ï¼š
    - ReasoningCache: è¿½è¸ªæ¨ç†çŠ¶æ€ï¼ŒåŒ…æ‹¬å­ç›®æ ‡ã€å·²çŸ¥äº‹å®ã€ç¼ºå¤±ä¿¡æ¯
    - Reasoner: åˆ†æé—®é¢˜ç±»å‹ï¼Œè¿›è¡Œæ¨ç†è§„åˆ’å’Œç»“è®ºç”Ÿæˆ
    - Summarizer: ç­›é€‰æœ‰ç”¨ä¿¡æ¯ï¼Œç”Ÿæˆæ¨ç†æ€»ç»“
    """
    
    def __init__(
        self,
        storage_paths: Union[str, List[str]] = None,
        storage_managers: List[Any] = None,
        llm_config: Dict[str, Any] = None,
        config: AgentConfig = None,
        verbose: bool = True,
        log_level: str = "moderate"
    ):
        """
        åˆå§‹åŒ–è®°å¿†æ£€ç´¢ Agent
        
        Args:
            storage_paths: è®°å¿†åº“è·¯å¾„ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            storage_managers: StorageManager å®ä¾‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸ storage_paths äºŒé€‰ä¸€ï¼‰
            llm_config: LLM é…ç½®å­—å…¸ï¼ŒåŒ…å« api_key, base_url, model ç­‰
            config: AgentConfig é…ç½®å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
            verbose: æ˜¯å¦æ‰“å°å†³ç­–é“¾è·¯
            log_level: æ—¥å¿—çº§åˆ« (minimal, moderate, verbose)
        """
        # åˆå§‹åŒ–é…ç½®
        self.config = config or AgentConfig()
        if llm_config:
            self.config.llm_api_key = llm_config.get("api_key", "")
            self.config.llm_base_url = llm_config.get("base_url", "https://api.openai.com/v1")
            self.config.llm_model = llm_config.get("model", "gpt-4")
            self.config.llm_temperature = llm_config.get("temperature", 0.7)
            self.config.llm_max_tokens = llm_config.get("max_tokens", 4096)
        
        self.config.verbose = verbose
        self.config.log_level = log_level
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = AgentLogger(
            level=log_level if verbose else "minimal",
            enable_colors=True
        )
        set_logger(self.logger)
        
        # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
        self.storage_managers = []
        if storage_managers:
            self.storage_managers = storage_managers
        elif storage_paths:
            paths = [storage_paths] if isinstance(storage_paths, str) else storage_paths
            self._init_storage_managers(paths)
        
        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.llm_client = self._create_llm_client()
        
        # åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨ï¼ˆä¸ºæ¯ä¸ªå­˜å‚¨ç®¡ç†å™¨åˆ›å»ºï¼‰
        self.tool_registries: List[ToolRegistry] = []
        for sm in self.storage_managers:
            self.tool_registries.append(create_default_registry(sm))
        
        # å¦‚æœæ²¡æœ‰å­˜å‚¨ç®¡ç†å™¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„æ³¨å†Œè¡¨ç”¨äºæµ‹è¯•
        if not self.tool_registries:
            self.tool_registries.append(ToolRegistry())
        
        # åˆå§‹åŒ–æ¨ç†ç¼“å­˜
        self.reasoning_cache = ReasoningCache()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.planner = Planner(
            llm_client=self.llm_client,
            tools=self.tool_registries[0].get_all_definitions(),
            logger=self.logger
        )
        
        self.executors = [
            Executor(
                tool_registry=registry,
                parallel=self.config.parallel_tools,
                timeout=self.config.tool_timeout,
                logger=self.logger
            )
            for registry in self.tool_registries
        ]
        
        self.evaluator = Evaluator(
            llm_client=self.llm_client,
            logger=self.logger
        )
        
        # åˆå§‹åŒ–æ¨ç†å™¨
        self.reasoner = Reasoner(
            llm_client=self.llm_client,
            reasoning_cache=self.reasoning_cache,
            logger=self.logger
        )
        
        # åˆå§‹åŒ–æ€»ç»“å™¨
        self.summarizer = Summarizer(
            llm_client=self.llm_client,
            logger=self.logger
        )
        
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡å’Œç¼“å­˜
        self.context_manager = ContextManager(llm_client=self.llm_client)
        self.cache = SmartCache() if self.config.enable_cache else None
    
    def _init_storage_managers(self, paths: List[str]):
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨"""
        try:
            from processor.storage import StorageManager
            from processor.embedding_client import EmbeddingClient
            
            # åˆ›å»º embedding å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            embedding_client = None
            if self.config.embedding_model_path:
                embedding_client = EmbeddingClient(
                    model_path=self.config.embedding_model_path,
                    device=self.config.embedding_device
                )
            
            for path in paths:
                sm = StorageManager(
                    storage_path=path,
                    embedding_client=embedding_client
                )
                self.storage_managers.append(sm)
                
        except ImportError as e:
            self.logger.warning(f"æ— æ³•å¯¼å…¥ StorageManager: {e}")
            self.logger.warning("è¯·ç¡®ä¿ processor æ¨¡å—å¯ç”¨ï¼Œæˆ–ç›´æ¥ä¼ å…¥ storage_managers å‚æ•°")
    
    def _create_llm_client(self) -> BaseLLMClient:
        """åˆ›å»º LLM å®¢æˆ·ç«¯"""
        if not self.config.llm_api_key:
            # æ²¡æœ‰é…ç½® API Keyï¼Œä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯
            self.logger.warning("æœªé…ç½® LLM API Keyï¼Œä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯")
            return MockLLMClient()
        
        return create_llm_client(
            provider="custom",
            api_key=self.config.llm_api_key,
            base_url=self.config.llm_base_url,
            model=self.config.llm_model,
            temperature=self.config.llm_temperature,
            max_tokens=self.config.llm_max_tokens
        )
    
    def query(
        self,
        messages: Union[List[Dict[str, str]], str],
        enable_reasoning: bool = True,
        **kwargs
    ) -> QueryResult:
        """
        åŒæ­¥æŸ¥è¯¢æ¥å£
        
        Args:
            messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæˆ–ç›´æ¥ä¼ å…¥é—®é¢˜å­—ç¬¦ä¸²
            enable_reasoning: æ˜¯å¦å¯ç”¨æ¨ç†åŠŸèƒ½ï¼ˆåˆ†æé—®é¢˜ã€ç”Ÿæˆæ€»ç»“ï¼‰
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            QueryResult å¯¹è±¡
        """
        # æ ‡å‡†åŒ–è¾“å…¥
        if isinstance(messages, str):
            question = messages
            conversation_history = []
        else:
            # æå–é—®é¢˜ï¼ˆæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
            question = ""
            conversation_history = []
            for msg in messages:
                if msg.get("role") == "user":
                    question = msg.get("content", "")
                conversation_history.append(msg)
        
        if not question:
            return QueryResult(
                reasoning_trace=[{"error": "æœªæä¾›é—®é¢˜"}]
            )
        
        # å¼€å§‹æŸ¥è¯¢
        start_time = time.time()
        self.logger.start_query(question)
        
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        context = self.context_manager.start_query(question)
        
        try:
            # 1. åˆ†æé—®é¢˜ï¼ˆå¦‚æœå¯ç”¨æ¨ç†ï¼‰
            if enable_reasoning:
                self.logger.info("åˆ†æé—®é¢˜ç±»å‹...")
                reasoning_state = self.reasoner.analyze_question(question)
                self.logger.info(f"é—®é¢˜ç±»å‹: {reasoning_state.question_type.value}")
            else:
                reasoning_state = None
            
            # 2. ReAct å¾ªç¯
            iteration = 0
            while iteration < self.config.max_iterations:
                iteration += 1
                self.context_manager.increment_iteration()
                self.logger.iteration(iteration, self.config.max_iterations)
                
                # è·å–æ¨ç†çŠ¶æ€æ‘˜è¦
                reasoning_state_str = None
                if reasoning_state:
                    reasoning_state_str = self.reasoning_cache.get_state_summary()
                
                # 2.1 è§„åˆ’
                plan = self.planner.plan(
                    question=question,
                    collected_info=self.context_manager.get_collected_info(),
                    reasoning_state=reasoning_state_str
                )
                
                self.context_manager.add_reasoning_step(
                    "plan",
                    plan.get("analysis", ""),
                    {"tool_calls": [tc.tool_name for tc in plan.get("tool_calls", [])]}
                )
                
                # è®°å½•è§„åˆ’
                tool_calls = plan.get("tool_calls", [])
                self.logger.plan(
                    plan.get("analysis", "è§„åˆ’ä¸­..."),
                    tool_calls
                )
                
                # æ£€æŸ¥æ˜¯å¦è§„åˆ’å™¨è®¤ä¸ºå·²å®Œæˆ
                if plan.get("is_complete", False) or not tool_calls:
                    self.logger.info("è§„åˆ’å™¨åˆ¤æ–­ä¿¡æ¯å·²å……è¶³")
                    break
                
                # 2.2 æ‰§è¡Œï¼ˆå¯¹æ‰€æœ‰å­˜å‚¨ç®¡ç†å™¨ï¼‰
                all_results = []
                for executor in self.executors:
                    results = executor.execute(tool_calls)
                    all_results.extend(results)
                    
                    # æ·»åŠ ç»“æœåˆ°ä¸Šä¸‹æ–‡
                    for result in results:
                        self.context_manager.add_tool_result(result.tool_name, result)
                        
                        # è®°å½•åˆ°æ¨ç†ç¼“å­˜
                        if reasoning_state and result.data:
                            self.reasoning_cache.record_query(
                                tool_name=result.tool_name,
                                parameters={},  # ç®€åŒ–
                                iteration=iteration,
                                success=result.is_success,
                                result_summary=result.data.get("message", "") if isinstance(result.data, dict) else ""
                            )
                
                # 2.3 æ•´åˆäº‹å®ï¼ˆå¦‚æœå¯ç”¨æ¨ç†ï¼‰
                if reasoning_state:
                    self.reasoner.integrate_facts(self.context_manager.get_collected_info())
                
                # 2.4 å°è¯•å¾—å‡ºç»“è®º
                if reasoning_state:
                    can_conclude, conclusion, confidence = self.reasoner.try_conclude()
                    if can_conclude:
                        self.logger.info(f"æ¨ç†å™¨å¾—å‡ºç»“è®ºï¼ˆç½®ä¿¡åº¦: {confidence:.0%}ï¼‰")
                        self.logger.info(f"  [ç»“è®º] {conclusion[:200]}..." if len(conclusion) > 200 else f"  [ç»“è®º] {conclusion}")
                        # è¾“å‡ºæ¨ç†ä¾æ®
                        state = self.reasoner.cache.state
                        if state and state.known_facts:
                            # è¾“å‡ºæ¨ç†é“¾
                            reasoning_steps = [(k, v) for k, v in sorted(state.known_facts.items()) if k.startswith("reasoning_step")]
                            if reasoning_steps:
                                self.logger.info("  [æ¨ç†é“¾]")
                                for _, step in reasoning_steps:
                                    self.logger.info(f"    - {step}")
                            # è¾“å‡ºè¯æ®
                            evidence = [(k, v) for k, v in sorted(state.known_facts.items()) if k.startswith("evidence")]
                            if evidence:
                                self.logger.info("  [è¯æ®]")
                                for _, ev in evidence:
                                    self.logger.info(f"    - {ev[:100]}..." if len(ev) > 100 else f"    - {ev}")
                        break
                
                # 2.5 è¯„ä¼°
                eval_result = self.evaluator.evaluate(
                    question=question,
                    collected_memories=self.context_manager.get_collected_info(),
                    iteration=iteration,
                    reasoning_state=reasoning_state
                )
                
                # 2.5.1 æ£€æŸ¥é—®é¢˜ç±»å‹è°ƒæ•´å»ºè®®
                if eval_result.question_type_adjustment and eval_result.question_type_adjustment.should_adjust:
                    new_type_str = eval_result.question_type_adjustment.new_type
                    if new_type_str and reasoning_state:
                        from agent.context.reasoning_cache import QuestionType
                        try:
                            new_type = QuestionType(new_type_str)
                            old_type = reasoning_state.question_type
                            if new_type != old_type:
                                self.logger.info(f"ğŸ”„ é—®é¢˜ç±»å‹è°ƒæ•´: {old_type.value} â†’ {new_type.value}")
                                self.logger.info(f"   åŸå› : {eval_result.question_type_adjustment.reason}")
                                # æ›´æ–°æ¨ç†çŠ¶æ€çš„é—®é¢˜ç±»å‹ï¼ˆä¿ç•™å·²æœ‰çš„äº‹å®å’Œå­ç›®æ ‡ï¼‰
                                reasoning_state.question_type = new_type
                                # æ ¹æ®æ–°ç±»å‹æ·»åŠ ç¼ºå¤±çš„å­ç›®æ ‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                                if new_type == QuestionType.TEMPORAL_REASONING:
                                    # æ—¶åºæ¨ç†éœ€è¦æ—¶é—´æ’åºç›¸å…³çš„å­ç›®æ ‡
                                    if not any("æ—¶é—´" in g.description or "é¡ºåº" in g.description 
                                             for g in reasoning_state.sub_goals):
                                        self.reasoner.cache.add_sub_goal(
                                            description="æŒ‰æ—¶é—´æ’åºç›¸å…³äº‹ä»¶",
                                            depends_on=[]
                                        )
                        except ValueError:
                            self.logger.warning(f"æ— æ•ˆçš„é—®é¢˜ç±»å‹: {new_type_str}")
                
                self.context_manager.add_reasoning_step(
                    "evaluate",
                    eval_result.reasoning,
                    {"is_sufficient": eval_result.is_sufficient}
                )
                
                # 2.6 åˆ¤æ–­æ˜¯å¦ç»§ç»­
                if eval_result.is_sufficient:
                    self.logger.info("è¯„ä¼°å™¨åˆ¤æ–­ä¿¡æ¯å·²å……è¶³")
                    break
                
                # æ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´ä¸Šä¸‹æ–‡
                if eval_result.memories_to_keep:
                    self.context_manager.prune_memories(eval_result.memories_to_keep)
            
            # 3. ç”Ÿæˆæ€»ç»“ï¼ˆå¦‚æœå¯ç”¨æ¨ç†ï¼‰
            summary_result = None
            if enable_reasoning and reasoning_state:
                self.logger.info("ç”Ÿæˆæ¨ç†æ€»ç»“...")
                summary_result = self.summarizer.summarize(reasoning_state)
            
            # 4. æ„å»ºç»“æœ
            execution_time = time.time() - start_time
            
            result = QueryResult(
                retrieved_memories=self.context_manager.build_retrieved_memories(),
                relevant_entities=self.context_manager.get_relevant_entities(),
                relevant_relations=self.context_manager.get_relevant_relations(),
                reasoning_trace=self.context_manager.get_reasoning_trace(),
                total_iterations=iteration,
                total_tool_calls=len(context.tool_results),
                execution_time=execution_time
            )
            
            # æ·»åŠ æ¨ç†æ€»ç»“åˆ°ç»“æœ
            if summary_result:
                result.reasoning_trace.append({
                    "type": "summary",
                    "answer": summary_result.answer,
                    "confidence": summary_result.confidence,
                    "reasoning_chain": summary_result.reasoning_chain,
                    "context_text": summary_result.context_text
                })
            
            self.logger.complete(iteration, len(context.tool_results), execution_time)
            
            return result
            
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢å¤±è´¥: {str(e)}", e)
            import traceback
            traceback.print_exc()
            return QueryResult(
                reasoning_trace=[{"error": str(e)}],
                execution_time=time.time() - start_time
            )
    
    async def aquery(
        self,
        messages: Union[List[Dict[str, str]], str],
        enable_reasoning: bool = True,
        **kwargs
    ) -> QueryResult:
        """
        å¼‚æ­¥æŸ¥è¯¢æ¥å£
        
        Args:
            messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæˆ–ç›´æ¥ä¼ å…¥é—®é¢˜å­—ç¬¦ä¸²
            enable_reasoning: æ˜¯å¦å¯ç”¨æ¨ç†åŠŸèƒ½
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            QueryResult å¯¹è±¡
        """
        # æ ‡å‡†åŒ–è¾“å…¥
        if isinstance(messages, str):
            question = messages
            conversation_history = []
        else:
            question = ""
            conversation_history = []
            for msg in messages:
                if msg.get("role") == "user":
                    question = msg.get("content", "")
                conversation_history.append(msg)
        
        if not question:
            return QueryResult(
                reasoning_trace=[{"error": "æœªæä¾›é—®é¢˜"}]
            )
        
        start_time = time.time()
        self.logger.start_query(question)
        
        context = self.context_manager.start_query(question)
        
        try:
            # 1. åˆ†æé—®é¢˜
            if enable_reasoning:
                reasoning_state = await self.reasoner.aanalyze_question(question)
            else:
                reasoning_state = None
            
            # 2. ReAct å¾ªç¯
            iteration = 0
            while iteration < self.config.max_iterations:
                iteration += 1
                self.context_manager.increment_iteration()
                self.logger.iteration(iteration, self.config.max_iterations)
                
                reasoning_state_str = None
                if reasoning_state:
                    reasoning_state_str = self.reasoning_cache.get_state_summary()
                
                # 2.1 å¼‚æ­¥è§„åˆ’
                plan = await self.planner.aplan(
                    question=question,
                    collected_info=self.context_manager.get_collected_info(),
                    reasoning_state=reasoning_state_str
                )
                
                self.context_manager.add_reasoning_step(
                    "plan",
                    plan.get("analysis", ""),
                    {"tool_calls": [tc.tool_name for tc in plan.get("tool_calls", [])]}
                )
                
                tool_calls = plan.get("tool_calls", [])
                self.logger.plan(plan.get("analysis", "è§„åˆ’ä¸­..."), tool_calls)
                
                if plan.get("is_complete", False) or not tool_calls:
                    self.logger.info("è§„åˆ’å™¨åˆ¤æ–­ä¿¡æ¯å·²å……è¶³")
                    break
                
                # 2.2 å¼‚æ­¥æ‰§è¡Œ
                all_results = []
                for executor in self.executors:
                    results = await executor.aexecute(tool_calls)
                    all_results.extend(results)
                    
                    for result in results:
                        self.context_manager.add_tool_result(result.tool_name, result)
                        
                        if reasoning_state and result.data:
                            self.reasoning_cache.record_query(
                                tool_name=result.tool_name,
                                parameters={},
                                iteration=iteration,
                                success=result.is_success,
                                result_summary=result.data.get("message", "") if isinstance(result.data, dict) else ""
                            )
                
                # 2.3 æ•´åˆäº‹å®
                if reasoning_state:
                    self.reasoner.integrate_facts(self.context_manager.get_collected_info())
                
                # 2.4 å°è¯•å¾—å‡ºç»“è®º
                if reasoning_state:
                    can_conclude, conclusion, confidence = await self.reasoner.atry_conclude()
                    if can_conclude:
                        self.logger.info(f"æ¨ç†å™¨å¾—å‡ºç»“è®ºï¼ˆç½®ä¿¡åº¦: {confidence:.0%}ï¼‰")
                        self.logger.info(f"  [ç»“è®º] {conclusion[:200]}..." if len(conclusion) > 200 else f"  [ç»“è®º] {conclusion}")
                        # è¾“å‡ºæ¨ç†ä¾æ®
                        state = self.reasoner.cache.state
                        if state and state.known_facts:
                            # è¾“å‡ºæ¨ç†é“¾
                            reasoning_steps = [(k, v) for k, v in sorted(state.known_facts.items()) if k.startswith("reasoning_step")]
                            if reasoning_steps:
                                self.logger.info("  [æ¨ç†é“¾]")
                                for _, step in reasoning_steps:
                                    self.logger.info(f"    - {step}")
                            # è¾“å‡ºè¯æ®
                            evidence = [(k, v) for k, v in sorted(state.known_facts.items()) if k.startswith("evidence")]
                            if evidence:
                                self.logger.info("  [è¯æ®]")
                                for _, ev in evidence:
                                    self.logger.info(f"    - {ev[:100]}..." if len(ev) > 100 else f"    - {ev}")
                        break
                
                # 2.5 å¼‚æ­¥è¯„ä¼°
                eval_result = await self.evaluator.aevaluate(
                    question=question,
                    collected_memories=self.context_manager.get_collected_info(),
                    iteration=iteration,
                    reasoning_state=reasoning_state
                )
                
                # 2.5.1 æ£€æŸ¥é—®é¢˜ç±»å‹è°ƒæ•´å»ºè®®
                if eval_result.question_type_adjustment and eval_result.question_type_adjustment.should_adjust:
                    new_type_str = eval_result.question_type_adjustment.new_type
                    if new_type_str and reasoning_state:
                        from agent.context.reasoning_cache import QuestionType
                        try:
                            new_type = QuestionType(new_type_str)
                            old_type = reasoning_state.question_type
                            if new_type != old_type:
                                self.logger.info(f"ğŸ”„ é—®é¢˜ç±»å‹è°ƒæ•´: {old_type.value} â†’ {new_type.value}")
                                self.logger.info(f"   åŸå› : {eval_result.question_type_adjustment.reason}")
                                # æ›´æ–°æ¨ç†çŠ¶æ€çš„é—®é¢˜ç±»å‹ï¼ˆä¿ç•™å·²æœ‰çš„äº‹å®å’Œå­ç›®æ ‡ï¼‰
                                reasoning_state.question_type = new_type
                                # æ ¹æ®æ–°ç±»å‹æ·»åŠ ç¼ºå¤±çš„å­ç›®æ ‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                                if new_type == QuestionType.TEMPORAL_REASONING:
                                    # æ—¶åºæ¨ç†éœ€è¦æ—¶é—´æ’åºç›¸å…³çš„å­ç›®æ ‡
                                    if not any("æ—¶é—´" in g.description or "é¡ºåº" in g.description 
                                             for g in reasoning_state.sub_goals):
                                        self.reasoner.cache.add_sub_goal(
                                            description="æŒ‰æ—¶é—´æ’åºç›¸å…³äº‹ä»¶",
                                            depends_on=[]
                                        )
                        except ValueError:
                            self.logger.warning(f"æ— æ•ˆçš„é—®é¢˜ç±»å‹: {new_type_str}")
                
                self.context_manager.add_reasoning_step(
                    "evaluate",
                    eval_result.reasoning,
                    {"is_sufficient": eval_result.is_sufficient}
                )
                
                if eval_result.is_sufficient:
                    self.logger.info("è¯„ä¼°å™¨åˆ¤æ–­ä¿¡æ¯å·²å……è¶³")
                    break
                
                if eval_result.memories_to_keep:
                    self.context_manager.prune_memories(eval_result.memories_to_keep)
            
            # 3. ç”Ÿæˆæ€»ç»“
            summary_result = None
            if enable_reasoning and reasoning_state:
                summary_result = await self.summarizer.asummarize(reasoning_state)
            
            # 4. æ„å»ºç»“æœ
            execution_time = time.time() - start_time
            result = QueryResult(
                retrieved_memories=self.context_manager.build_retrieved_memories(),
                relevant_entities=self.context_manager.get_relevant_entities(),
                relevant_relations=self.context_manager.get_relevant_relations(),
                reasoning_trace=self.context_manager.get_reasoning_trace(),
                total_iterations=iteration,
                total_tool_calls=len(context.tool_results),
                execution_time=execution_time
            )
            
            if summary_result:
                result.reasoning_trace.append({
                    "type": "summary",
                    "answer": summary_result.answer,
                    "confidence": summary_result.confidence,
                    "reasoning_chain": summary_result.reasoning_chain,
                    "context_text": summary_result.context_text
                })
            
            self.logger.complete(iteration, len(context.tool_results), execution_time)
            
            return result
            
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢å¤±è´¥: {str(e)}", e)
            return QueryResult(
                reasoning_trace=[{"error": str(e)}],
                execution_time=time.time() - start_time
            )
    
    def get_context_text(self, result: QueryResult) -> str:
        """
        è·å–ç”¨äºå¤–éƒ¨ LLM çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        
        Args:
            result: æŸ¥è¯¢ç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        # ä¼˜å…ˆä½¿ç”¨æ¨ç†æ€»ç»“ä¸­çš„ä¸Šä¸‹æ–‡
        for trace in result.reasoning_trace:
            if isinstance(trace, dict) and trace.get("type") == "summary":
                context_text = trace.get("context_text", "")
                if context_text:
                    return context_text
        
        return result.get_context_text()
    
    def get_answer(self, result: QueryResult) -> Optional[str]:
        """
        è·å–æ¨ç†å¾—å‡ºçš„ç­”æ¡ˆ
        
        Args:
            result: æŸ¥è¯¢ç»“æœ
            
        Returns:
            ç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
        """
        for trace in result.reasoning_trace:
            if isinstance(trace, dict) and trace.get("type") == "summary":
                return trace.get("answer")
        return None
    
    def get_confidence(self, result: QueryResult) -> float:
        """
        è·å–ç­”æ¡ˆçš„ç½®ä¿¡åº¦
        
        Args:
            result: æŸ¥è¯¢ç»“æœ
            
        Returns:
            ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
        """
        for trace in result.reasoning_trace:
            if isinstance(trace, dict) and trace.get("type") == "summary":
                return trace.get("confidence", 0.0)
        return 0.0
    
    def add_storage(self, storage_path: str = None, storage_manager: Any = None):
        """
        æ·»åŠ è®°å¿†åº“
        
        Args:
            storage_path: è®°å¿†åº“è·¯å¾„
            storage_manager: StorageManager å®ä¾‹
        """
        if storage_manager:
            self.storage_managers.append(storage_manager)
            registry = create_default_registry(storage_manager)
            self.tool_registries.append(registry)
            self.executors.append(
                Executor(
                    tool_registry=registry,
                    parallel=self.config.parallel_tools,
                    timeout=self.config.tool_timeout,
                    logger=self.logger
                )
            )
        elif storage_path:
            self._init_storage_managers([storage_path])
            if self.storage_managers:
                sm = self.storage_managers[-1]
                registry = create_default_registry(sm)
                self.tool_registries.append(registry)
                self.executors.append(
                    Executor(
                        tool_registry=registry,
                        parallel=self.config.parallel_tools,
                        timeout=self.config.tool_timeout,
                        logger=self.logger
                    )
                )
