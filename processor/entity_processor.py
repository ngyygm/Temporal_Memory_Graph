"""
å®ä½“å¤„ç†æ¨¡å—ï¼šå®ä½“æœç´¢ã€å¯¹é½ã€æ›´æ–°/æ–°å»º
"""
from typing import List, Dict, Optional
from datetime import datetime
import uuid

from .models import Entity, MemoryCache
from .storage import StorageManager
from .llm_client import LLMClient


class EntityProcessor:
    """å®ä½“å¤„ç†å™¨ - è´Ÿè´£å®ä½“çš„æœç´¢ã€å¯¹é½ã€æ›´æ–°å’Œæ–°å»º"""
    
    def __init__(self, storage: StorageManager, llm_client: LLMClient,
                 max_similar_entities: int = 10, content_snippet_length: int = 50):
        self.storage = storage
        self.llm_client = llm_client
        self.max_similar_entities = max_similar_entities
        self.content_snippet_length = content_snippet_length
    
    def process_entities(self, extracted_entities: List[Dict[str, str]], 
                        memory_cache_id: str, similarity_threshold: float = 0.7,
                        memory_cache: Optional[MemoryCache] = None, doc_name: str = "") -> List[Entity]:
        """
        å¤„ç†æŠ½å–çš„å®ä½“ï¼šæœç´¢ã€å¯¹é½ã€æ›´æ–°/æ–°å»º
        
        Args:
            extracted_entities: æŠ½å–çš„å®ä½“åˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å«nameå’Œcontentï¼‰
            memory_cache_id: å½“å‰è®°å¿†ç¼“å­˜çš„ID
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆç”¨äºæœç´¢ï¼‰
            memory_cache: å½“å‰è®°å¿†ç¼“å­˜å¯¹è±¡ï¼ˆå¯é€‰ï¼Œç”¨äºLLMåˆ¤æ–­æ—¶æä¾›ä¸Šä¸‹æ–‡ï¼‰
            doc_name: æ–‡æ¡£åç§°ï¼ˆåªä¿å­˜æ–‡æ¡£åï¼Œä¸åŒ…å«è·¯å¾„ï¼‰
        
        Returns:
            å¤„ç†åçš„å®ä½“åˆ—è¡¨ï¼ˆå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
        """
        processed_entities = []
        
        for extracted_entity in extracted_entities:
            entity = self._process_single_entity(
                extracted_entity, 
                memory_cache_id, 
                similarity_threshold,
                memory_cache,
                doc_name
            )
            if entity:
                processed_entities.append(entity)
        
        return processed_entities
    
    def _process_single_entity(self, extracted_entity: Dict[str, str], 
                               memory_cache_id: str, 
                               similarity_threshold: float,
                               memory_cache: Optional[MemoryCache] = None,
                               doc_name: str = "") -> Optional[Entity]:
        """
        å¤„ç†å•ä¸ªå®ä½“
        
        æµç¨‹ï¼š
        1. æ ¹æ®è¯ç›¸ä¼¼åº¦æœç´¢ç›¸å…³å®ä½“ï¼ˆä½¿ç”¨ name + content[:50] æ”¾å®½è¦æ±‚ï¼‰
        2. æ‰¾åˆ°åŒIDä¸‹æœ€æ–°çš„å®ä½“ï¼ˆå»é‡ï¼‰
        3. ç”¨LLMåˆ¤æ–­æ˜¯å¦åŒ¹é…ï¼ˆç»“åˆè®°å¿†ç¼“å­˜å’Œå®ä½“åç§°+å†…å®¹ï¼‰
        4. å¦‚æœåŒ¹é…ï¼Œæ›´æ–°ï¼›å¦‚æœä¸åŒ¹é…ï¼Œæ–°å»º
        """
        entity_name = extracted_entity['name']
        entity_content = extracted_entity['content']
        
        # æ­¥éª¤1ï¼šä½¿ç”¨ä¸¤ç§æ¨¡å¼æœç´¢ç›¸å…³å®ä½“å¹¶åˆå¹¶ç»“æœ
        # æ¨¡å¼1ï¼šåªç”¨nameæ£€ç´¢ï¼ˆæ›´ç²¾ç¡®ï¼Œé¿å…contentå¹²æ‰°ï¼‰
        # æ¨¡å¼2ï¼šä½¿ç”¨name+contentæ£€ç´¢ï¼ˆæ›´å…¨é¢ï¼Œæ•è·è¯­ä¹‰ç›¸ä¼¼ï¼‰
        half_results = max(1, self.max_similar_entities // 2)  # å¯¹åŠåˆ†ï¼Œè‡³å°‘1ä¸ª
        
        # æ¨¡å¼1ï¼šåªç”¨nameæ£€ç´¢ï¼ˆä½¿ç”¨embeddingæˆ–æ–‡æœ¬ç›¸ä¼¼åº¦ï¼‰
        similar_entities_name = self.storage.search_entities_by_similarity(
            entity_name,
            query_content=None,
            threshold=similarity_threshold,
            max_results=half_results,
            content_snippet_length=self.content_snippet_length,
            text_mode="name_only",
            similarity_method="embedding"  # ä¼˜å…ˆä½¿ç”¨embeddingï¼Œå¦‚æœä¸å¯ç”¨ä¼šè‡ªåŠ¨å›é€€
        )
        
        # æ¨¡å¼2ï¼šä½¿ç”¨name+contentæ£€ç´¢
        similar_entities_full = self.storage.search_entities_by_similarity(
            entity_name,
            query_content=entity_content,
            threshold=similarity_threshold,
            max_results=half_results,
            content_snippet_length=self.content_snippet_length,
            text_mode="name_and_content",
            similarity_method="embedding"  # ä¼˜å…ˆä½¿ç”¨embeddingï¼Œå¦‚æœä¸å¯ç”¨ä¼šè‡ªåŠ¨å›é€€
        )
        
        # åˆå¹¶ç»“æœå¹¶å»é‡ï¼ˆæŒ‰entity_idå»é‡ï¼Œä¿ç•™æ¯ä¸ªentity_idçš„æœ€æ–°ç‰ˆæœ¬ï¼‰
        entity_dict = {}
        for entity in similar_entities_name + similar_entities_full:
            if entity.entity_id not in entity_dict:
                entity_dict[entity.entity_id] = entity
            else:
                # ä¿ç•™ç‰©ç†æ—¶é—´æœ€æ–°çš„
                if entity.physical_time > entity_dict[entity.entity_id].physical_time:
                    entity_dict[entity.entity_id] = entity
        
        similar_entities = list(entity_dict.values())
        
        # å¦‚æœåˆå¹¶åè¶…è¿‡æœ€å¤§æ•°é‡ï¼ŒæŒ‰ç‰©ç†æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„
        if len(similar_entities) > self.max_similar_entities:
            similar_entities.sort(key=lambda e: e.physical_time, reverse=True)
            similar_entities = similar_entities[:self.max_similar_entities]
        
        if not similar_entities:
            # æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼å®ä½“ï¼Œç›´æ¥æ–°å»º
            return self._create_new_entity(entity_name, entity_content, memory_cache_id, doc_name)
        
        # æ­¥éª¤2ï¼šæ‰¾åˆ°åŒIDä¸‹æœ€æ–°çš„å®ä½“ï¼ˆå»é‡ï¼‰
        # æŒ‰entity_idåˆ†ç»„ï¼Œæ¯ä¸ªentity_idåªä¿ç•™æœ€æ–°ç‰ˆæœ¬
        entity_dict = {}
        for entity in similar_entities:
            if entity.entity_id not in entity_dict:
                entity_dict[entity.entity_id] = entity
            else:
                # ä¿ç•™ç‰©ç†æ—¶é—´æœ€æ–°çš„
                if entity.physical_time > entity_dict[entity.entity_id].physical_time:
                    entity_dict[entity.entity_id] = entity
        
        unique_entities = list(entity_dict.values())
        
        # æ­¥éª¤3ï¼šå‡†å¤‡å·²æœ‰å®ä½“ä¿¡æ¯ä¾›LLMåˆ¤æ–­
        existing_entities_info = [
            {
                'entity_id': e.entity_id,
                'name': e.name,
                'content': e.content
            }
            for e in unique_entities
        ]
        
        # æ­¥éª¤4ï¼šç”¨LLMåˆ¤æ–­æ˜¯å¦åŒ¹é…ï¼ˆä¼ å…¥è®°å¿†ç¼“å­˜ä»¥æä¾›ä¸Šä¸‹æ–‡ï¼‰
        match_result = self.llm_client.judge_entity_match(
            extracted_entity, 
            existing_entities_info,
            memory_cache=memory_cache
        )
        
        # ç¡®ä¿ match_result æ˜¯å­—å…¸æ ¼å¼
        if match_result and isinstance(match_result, dict) and match_result.get('entity_id'):
            # åŒ¹é…åˆ°å·²æœ‰å®ä½“
            entity_id = match_result['entity_id']
            
            # è·å–æœ€æ–°ç‰ˆæœ¬çš„content
            latest_entity = self.storage.get_entity_by_id(entity_id)
            if not latest_entity:
                # å¦‚æœæ‰¾ä¸åˆ°æœ€æ–°ç‰ˆæœ¬ï¼Œç›´æ¥æ–°å»º
                return self._create_new_entity(entity_name, entity_content, memory_cache_id, doc_name)
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°ï¼šæ¯”è¾ƒæœ€æ–°ç‰ˆæœ¬çš„contentå’Œå½“å‰æŠ½å–çš„content
            need_update = self.llm_client.judge_content_need_update(
                latest_entity.content,
                entity_content
            )
            
            if need_update:
                # éœ€è¦æ›´æ–°ï¼šåˆå¹¶åç§°å’Œå†…å®¹
                # è·å–æ•°æ®åº“ä¸­è¯¥entity_idçš„è®°å½•æ•°
                current_versions = self.storage.get_entity_versions(entity_id)
                record_count = len(current_versions)

                # åˆå¹¶åç§°ï¼ˆå¦‚æœåç§°ä¸åŒï¼‰
                if entity_name != latest_entity.name:
                    merged_name = self.llm_client.merge_entity_name(
                        latest_entity.name,
                        entity_name
                    )
                else:
                    merged_name = entity_name
                
                # åˆå¹¶å†…å®¹
                merged_content = self.llm_client.merge_entity_content(
                    latest_entity.content,
                    entity_content
                )

                # åˆ›å»ºæ–°ç‰ˆæœ¬
                print(f"[å®ä½“æ“ä½œ] ğŸ”„ æ›´æ–°å®ä½“: {entity_name} (entity_id: {entity_id}) - æ•°æ®åº“ä¸­è¯¥entity_idæœ‰ {record_count} ä¸ªç‰ˆæœ¬")
                if entity_name != latest_entity.name:
                    print(f"  åç§°åˆå¹¶: {latest_entity.name} + {entity_name} -> {merged_name}")
                print(f"  æ›´æ–°å‰content:")
                print(f"    {latest_entity.content[:200]}{'...' if len(latest_entity.content) > 200 else ''}")
                print(f"  æ–°æŠ½å–content:")
                print(f"    {entity_content[:200]}{'...' if len(entity_content) > 200 else ''}")
                print(f"  åˆå¹¶åcontent:")
                print(f"    {merged_content[:200]}{'...' if len(merged_content) > 200 else ''}")
                
                new_entity = self._create_entity_version(
                    entity_id,
                    merged_name,  # ä½¿ç”¨åˆå¹¶åçš„åç§°
                    merged_content,
                    memory_cache_id,
                    doc_name
                )
                
                # æŸ¥è¯¢æ›´æ–°åçš„ç‰ˆæœ¬æ•°é‡
                updated_versions = self.storage.get_entity_versions(entity_id)
                updated_count = len(updated_versions)
                print(f"  æ›´æ–°åï¼Œæ•°æ®åº“ä¸­è¯¥entity_idæœ‰ {updated_count} ä¸ªç‰ˆæœ¬")
                
                return new_entity
            else:
                # ä¸éœ€è¦æ›´æ–°ï¼Œè¿”å›æœ€æ–°ç‰ˆæœ¬
                # è·å–æ•°æ®åº“ä¸­è¯¥entity_idçš„ç‰ˆæœ¬æ•°é‡
                current_versions = self.storage.get_entity_versions(entity_id)
                version_count = len(current_versions)
                print(f"[å®ä½“æ“ä½œ] â­ï¸  åŒ¹é…ä½†æ— éœ€æ›´æ–°: {entity_name} (entity_id: {entity_id}, æ•°æ®åº“ä¸­æœ‰ {version_count} ä¸ªç‰ˆæœ¬, åŒ¹é…å®ä½“åç§°: {latest_entity.name})")
                return latest_entity
        else:
            # æ²¡æœ‰åŒ¹é…åˆ°ï¼Œæ–°å»ºå®ä½“
            return self._create_new_entity(entity_name, entity_content, memory_cache_id, doc_name)
    
    def _create_new_entity(self, name: str, content: str, memory_cache_id: str, doc_name: str = "") -> Entity:
        """åˆ›å»ºæ–°å®ä½“"""
        entity_id = f"ent_{uuid.uuid4().hex[:12]}"
        entity_record_id = f"entity_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        # åªä¿å­˜æ–‡æ¡£åï¼Œä¸åŒ…å«è·¯å¾„
        doc_name_only = doc_name.split('/')[-1] if doc_name else ""
        
        entity = Entity(
            id=entity_record_id,
            entity_id=entity_id,
            name=name,
            content=content,
            physical_time=datetime.now(),
            memory_cache_id=memory_cache_id,
            doc_name=doc_name_only
        )
        
        self.storage.save_entity(entity)
        
        # æŸ¥è¯¢æ•°æ®åº“ä¸­è¯¥entity_idçš„ç‰ˆæœ¬æ•°é‡ï¼ˆåˆ›å»ºååº”è¯¥æœ‰1ä¸ªç‰ˆæœ¬ï¼‰
        entity_versions = self.storage.get_entity_versions(entity_id)
        version_count = len(entity_versions)
        
        print(f"[å®ä½“æ“ä½œ] âœ… åˆ›å»ºæ–°å®ä½“: {name} (entity_id: {entity_id}, æ•°æ®åº“ä¸­æœ‰ {version_count} ä¸ªç‰ˆæœ¬)")
        return entity
    
    def _create_entity_version(self, entity_id: str, name: str, content: str, 
                              memory_cache_id: str, doc_name: str = "") -> Entity:
        """åˆ›å»ºå®ä½“çš„æ–°ç‰ˆæœ¬"""
        entity_record_id = f"entity_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        # åªä¿å­˜æ–‡æ¡£åï¼Œä¸åŒ…å«è·¯å¾„
        doc_name_only = doc_name.split('/')[-1] if doc_name else ""
        
        entity = Entity(
            id=entity_record_id,
            entity_id=entity_id,
            name=name,
            content=content,
            physical_time=datetime.now(),
            memory_cache_id=memory_cache_id,
            doc_name=doc_name_only
        )
        
        self.storage.save_entity(entity)
        return entity
    
    def get_entity_by_name(self, entity_name: str) -> Optional[Entity]:
        """æ ¹æ®åç§°è·å–å®ä½“ï¼ˆè¿”å›æœ€æ–°ç‰ˆæœ¬ï¼‰"""
        # ä½¿ç”¨name_onlyæ¨¡å¼ï¼Œæ›´ç²¾ç¡®
        similar_entities = self.storage.search_entities_by_similarity(
            entity_name,
            text_mode="name_only",
            similarity_method="embedding"
        )
        if similar_entities:
            # è¿”å›ç¬¬ä¸€ä¸ªï¼ˆå·²ç»æ˜¯æœ€æ–°çš„ï¼‰
            return similar_entities[0]
        return None
